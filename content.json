{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"Charles","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-05-06T05:49:20.000Z","updated":"2019-05-06T05:52:54.997Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"本文链接：&lt;%= post.title %&gt; 作者：charlesFeng 出处：http://fengjun2016.github.io/本文基于 知识共享署名-相同方式共享 4.0 国际许可协议发布，欢迎转载，演绎或用于商业目的，但是必须保留本文的署名charlesFeng及链接。"}],"posts":[{"title":"gorm 嵌套子查询使用实例记录","slug":"gorm 嵌套子查询","date":"2019-08-16T09:05:45.000Z","updated":"2019-08-16T09:15:25.718Z","comments":true,"path":"2019/08/16/gorm 嵌套子查询/","link":"","permalink":"http://yoursite.com/2019/08/16/gorm 嵌套子查询/","excerpt":"","text":"废话不多说 直接上代码演示效果 子查询 使用 *gorm.expr 进行子查询 // 后面是等价的实际的sql语句 12db.Where(\"amount &gt; ?\", DB.Table(\"orders\").Select(\"AVG(amount)\").Where(\"state = ?\", \"paid\").QueryExpr()).Find(&amp;orders)// SELECT * FROM \"orders\" WHERE \"orders\".\"deleted_at\" IS NULL AND (amount &gt; (SELECT AVG(amount) FROM \"orders\" WHERE (state = 'paid'))); 项目当中实际使用的场景12345678910111213141516171819202122232425262728293031func (user *User) ListUnFavor(offDisplay []string, rawQuery string, rawOrder string, offset int, limit int) (*[]User, int, error) &#123; users := []User&#123;&#125; total := 0 db := app.DB.Model(user) if len(offDisplay) != 0 &#123; db.Where(\"`user`.id not in (?)\", offDisplay) &#125; db.Where(\"`user`.id not in (?)\", app.DB.Model(UserFollow&#123;&#125;).Select(\"user_id\").Where(\"`user_follow`.user_id = ? \", user.Id).QueryExpr()). Preload(\"UserPhone\").Preload(\"UserInfo\") db, err := buildWhere(rawQuery, db) if err != nil &#123; return &amp;users, total, err &#125; db, err = buildOrder(rawOrder, db) if err != nil &#123; return &amp;users, total, err &#125; db.Offset(offset). Limit(limit). Find(&amp;users). Count(&amp;total) err = db.Error return &amp;users, total, err&#125;","categories":[],"tags":[{"name":"golang es","slug":"golang-es","permalink":"http://yoursite.com/tags/golang-es/"}]},{"title":"golang elastic search 使用教程记录","slug":"golang elastic search","date":"2019-08-16T06:44:45.000Z","updated":"2019-08-16T06:45:09.723Z","comments":true,"path":"2019/08/16/golang elastic search/","link":"","permalink":"http://yoursite.com/2019/08/16/golang elastic search/","excerpt":"","text":"","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"记录一次同事写的关于数字金额的bug经历","slug":"记录一次review同事代码的bug","date":"2019-08-16T06:09:45.000Z","updated":"2019-08-16T08:36:20.437Z","comments":true,"path":"2019/08/16/记录一次review同事代码的bug/","link":"","permalink":"http://yoursite.com/2019/08/16/记录一次review同事代码的bug/","excerpt":"","text":"前言 一次偶然的机会 我跟同事两个人都提交了同一个项目的合并请求, 然后我就顺便看了一眼他的提交变化历史,但是没有仔细在意,然后后面在使用支付购买商品的时候,发现0.01的价值商品竟然无法购买, 支付宝提示交易金额异常,然后就发现他代码改动有写不对, 下面展示相关代码:和其改变提交代码的历史 12p.TotalAmount = fmt.Sprintf(\"%.2f\", float64(price/100))p.TotalAmount = fmt.Sprintf(\"%.2f\", float64(price)/100) 从上面的内容可以看到 他把float64的括号移动了一个位置,然后/是整数除法 如果price是一个int类型的话, 那么且price int 型还小于100 那么就会得到一个 0.00的金额 传到支付宝支付接口, 从而会导致金额异常 所以记录这一次同事的bug 并以此为戒","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"对从rpc获取来的二进制数据进行反解析成结构体进行二次处理","slug":"对从rpc获取来的数据进行反解析成结构体处理","date":"2019-08-15T07:48:53.000Z","updated":"2019-08-16T08:08:25.593Z","comments":true,"path":"2019/08/15/对从rpc获取来的数据进行反解析成结构体处理/","link":"","permalink":"http://yoursite.com/2019/08/15/对从rpc获取来的数据进行反解析成结构体处理/","excerpt":"","text":"对从rpc里面获取的数据进一步处理 业务当中处理过字段缺省问题 因为需要对从rpc里面获取的二进制数据解析成结构体 进行进一步的处理 所以这里需要进一步 处理成自定义的结构体 我在业务当中主要是由于要处理 字段是默认值 然后会被rpc在二进制流传输的过程中缺省的问题 代码示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253package blogimport ( \"blog-server/pkg/util\" \"bytes\" \"encoding/json\" \"log\" \"net/http\" \"reflect\" \"strconv\" \"time\" \"blog-server/model\" \"blog-server/pkg\" \"blog-server/rpc\" \"github.com/golang/protobuf/jsonpb\" \"github.com/ivpusic/neo\")var pbMarshaler jsonpb.Marshalerfunc init() &#123; pbMarshaler = jsonpb.Marshaler&#123; EmitDefaults: true, OrigName: true, EnumsAsInts: true, &#125;&#125;// 与proto定义字段 用于反序列化 解决protoc3协议缺省字段问题type RpcProduct struct &#123; Id string `json:\"id\"` UserId string `json:\"userId\"` CategoryId string `json:\"categoryId\"` CollectionId string `json:\"collectionId\"` Title string `json:\"title\"` Price string `json:\"price\"` Freight string `json:\"freight\"` Stock string `json:\"stock\"` Cover string `json:\"cover\"` Desc string `json:\"desc\"` Images string `json:\"images\"` Tags string `json:\"tags\"` Status string `json:\"status\"` CreatedAt string `json:\"createdAt\"` UpdatedAt string `json:\"updatedAt\"`&#125;func ListMyFollowWithProducts(c *neo.Ctx) (i int, e error) &#123; blog := &amp;model.Blog&#123;&#125; var err error currentUserId := c.Req.Header.Get(\"user_id\") pageParam := pkg.DefaultQuery(c, \"page\", \"-1\") pageSizeParam := pkg.DefaultQuery(c, \"pageSize\", \"-1\") pageInt, err := strconv.Atoi(pageParam) pageSizeInt, err := strconv.Atoi(pageSizeParam) offset := pageInt * pageSizeInt limit := pageSizeInt if offset &lt; 0 &#123; offset = 0 &#125; if currentUserId == \"\" &#123; return http.StatusBadRequest, c.Res.Json(map[string]interface&#123;&#125;&#123; \"total\": 0, \"data\": \"\", &#125;) &#125; rawQuery := \"status:=:published,reviewed:=:1\" rawOrder := \"created_at:desc\" //rpc获取我关注的用户id集合 rpcGetFollowRes, err := rpc.GetMyFollowUsers(currentUserId) if err != nil &#123; log.Println(\"rpc get my follow users userId-err:\", currentUserId, err) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; followUserIds := make([]string, 0) followUserIdsStr := \"\" for _, u := range rpcGetFollowRes.MyFollowUsers &#123; if u.UserId != \"\" &amp;&amp; u.UserId != currentUserId &#123; followUserIds = append(followUserIds, u.UserId) followUserIdsStr = followUserIdsStr + \",\" + u.UserId &#125; &#125; blogs, _, err := blog.ListForAdmin(true, followUserIds, rawQuery, rawOrder, 0, -1) if err != nil &#123; log.Println(\"get my follow users blog userId-err:\", currentUserId, err) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; //rpc获取products rpcGetMyFollowProductsRes, err := rpc.GetMyFollowProducts(followUserIdsStr) if err != nil &#123; log.Println(\"rpc get my follow products followUserIdsStr-err:\", followUserIdsStr, err) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; products := rpcGetMyFollowProductsRes.Products //rpc获取collections rpcGetMyFollowCollectionsRes, err := rpc.GetMyFollowCollections(followUserIdsStr) if err != nil &#123; log.Println(\"rpc get my follow collections followUserIdsStr-err:\", followUserIdsStr, err) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; collections := rpcGetMyFollowCollectionsRes.Collections blogsLength := len(*blogs) productsLength := len(products) collectionsLength := len(collections) timeTemplate := \"2006-01-02T15:04:05Z07:00\" response := make([]map[string]interface&#123;&#125;, 0) for _, b := range *blogs &#123; bRes := blogStructToMap(b) UserInfo := *rpc.GetUserInfo(b.UserId) UserInfo.Nick = util.BlockPhone(UserInfo.Nick) bRes[\"user\"] = UserInfo response = append(response, map[string]interface&#123;&#125;&#123; \"blog\": bRes, \"craetedUnix\": b.CreatedAt.Unix(), \"isThumb\": CheckIsThumb(currentUserId, b.Id), \"isStar\": CheckIsStar(currentUserId, b.Id), \"dataType\": \"blog\", &#125;) &#125; for _, p := range products &#123; pStamp, _ := time.ParseInLocation(timeTemplate, p.CreatedAt, time.Local) UserInfo := *rpc.GetUserInfo(p.UserId) UserInfo.Nick = util.BlockPhone(UserInfo.Nick) // Unmarshal pb object rpcProduct := RpcProduct&#123;&#125; buffer := bytes.NewBuffer([]byte&#123;&#125;) //关键步骤在这里 pbMarshaler.Marshal(buffer, p) log.Println(\"rpcProduct:\", buffer) json.Unmarshal(buffer.Bytes(), &amp;rpcProduct) rpcProductMap := dealRpcResNumberDataType(rpcProduct) response = append(response, map[string]interface&#123;&#125;&#123; \"product\": rpcProductMap, \"craetedUnix\": pStamp.Unix(), \"user\": UserInfo, \"isStar\": CheckIsStar(currentUserId, p.Id), \"dataType\": \"product\", &#125;) &#125; for _, c := range collections &#123; pStamp, _ := time.ParseInLocation(timeTemplate, c.CreatedAt, time.Local) UserInfo := *rpc.GetUserInfo(c.UserId) UserInfo.Nick = util.BlockPhone(UserInfo.Nick) response = append(response, map[string]interface&#123;&#125;&#123; \"collection\": c, \"craetedUnix\": pStamp.Unix(), \"user\": UserInfo, \"dataType\": \"collection\", &#125;) &#125; total := blogsLength + productsLength + collectionsLength //按照创建时间进行排序 for i := 0; i &lt; total - 1; i++ &#123; for j := total - 1; j &gt; i; j-- &#123; if response[j][\"craetedUnix\"].(int64) &gt; response[j-1][\"craetedUnix\"].(int64) &#123; temp := response[j-1] response[j-1] = response[j] response[j] = temp &#125; &#125; &#125; //进行分页处理 result := make([]map[string]interface&#123;&#125;, 0) if limit &gt;= 0 &#123; var end int if offset+limit &lt; total &#123; end = offset + limit &#125; else &#123; end = total &#125; log.Println(\"offset-limit:\", offset, limit) for k := offset; k &lt; end; k++ &#123; result = append(result, response[k]) &#125; &#125; else &#123; result = response &#125; return http.StatusOK, c.Res.Json(map[string]interface&#123;&#125;&#123; \"total\": total, \"data\": result, &#125;)&#125;func blogStructToMap(blog model.Blog) map[string]interface&#123;&#125; &#123; data := make(map[string]interface&#123;&#125;) data[\"id\"] = blog.Id data[\"createdAt\"] = blog.CreatedAt data[\"updatedAt\"] = blog.UpdatedAt data[\"deletedAt\"] = blog.DeletedAt data[\"type\"] = blog.Type data[\"userId\"] = blog.UserId data[\"title\"] = blog.Title data[\"summary\"] = blog.Summary data[\"cover\"] = blog.Cover data[\"content\"] = blog.Content data[\"thumbNum\"] = blog.ThumbNum data[\"starNum\"] = blog.StarNum data[\"location\"] = blog.Location data[\"status\"] = blog.Status data[\"from\"] = blog.From data[\"sourceUrl\"] = blog.SourceUrl data[\"sourceAuthor\"] = blog.SourceAuthor data[\"remark\"] = blog.Remark data[\"recommend\"] = blog.Recommend data[\"reviewed\"] = blog.Reviewed data[\"comments\"] = blog.Comments data[\"tags\"] = blog.Tags return data&#125;//将结构体转换成mapfunc structToMap(structData interface&#123;&#125;) map[string]interface&#123;&#125; &#123; data := make(map[string]interface&#123;&#125;) structDataType := reflect.TypeOf(structData) structDataValue := reflect.ValueOf(structData) for i := 0; i &lt; structDataType.NumField(); i++ &#123; data[structDataType.Field(i).Tag.Get(\"json\")] = structDataValue.Field(i).Interface() &#125; return data&#125;func dealRpcResNumberDataType(rpcProduct RpcProduct) map[string]interface&#123;&#125; &#123; data := structToMap(rpcProduct) data[\"categoryId\"], _ = strconv.Atoi(data[\"categoryId\"].(string)) data[\"collectionId\"], _ = strconv.Atoi(data[\"collectionId\"].(string)) data[\"price\"], _ = strconv.Atoi(data[\"price\"].(string)) data[\"freight\"], _ = strconv.Atoi(data[\"freight\"].(string)) data[\"stock\"], _ = strconv.Atoi(data[\"stock\"].(string)) data[\"status\"], _ = strconv.Atoi(data[\"status\"].(string)) return data&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"redis实现倒计时自动取消(关闭)订单","slug":"倒计时取消订单实现","date":"2019-07-25T02:30:45.000Z","updated":"2019-08-16T06:23:29.240Z","comments":true,"path":"2019/07/25/倒计时取消订单实现/","link":"","permalink":"http://yoursite.com/2019/07/25/倒计时取消订单实现/","excerpt":"","text":"几种思路 使用定时任务不断轮询取消，此种方式实现简单，但是存在一个问题，定时任务设置时间较短时，耗费资源，设置时间过长，则会导致有一些订单超过三小时很久才能取消，用户体验不好 在拉取我的订单时，进行判断然后做取消操作，此种方法，用户体验较好，但是在拉取订单列表的时候耦合了取消订单的操作，从系统的设计角度考虑不是很好。 使用DelayQueue队列和redis以及监听器设计，此种方式用户体验好，与其他功能耦合性低，但是用户量有所限制 数据库定时作业：写个存储过程实现订单后一个小时未付款则订单自动取消的功能，然后增加给数据库增加个维护计划定时执行这个存储过程。 此种方式用户体验好，与其他功能耦合性低，但是由于是写在数据库中，对外不可见，代码维护难度高 具体实现方式一、方式二都比较容易实现，这里不再讲述，本文讲述一下方式三的实现，方式四暂且不讲。 在生成订单时，向Redis中增加一个KV键值对，K为订单号，或者订单id，保证通过K能定位到数据库中的某个订单即可，V可为任意值（后边会解释为什么V可为任意值）。 假设，生成订单时向Redis中存放K为订单号，V也为订单号的键值对，并设置过期时间为30分装，如果该键值对在30分钟过期后能够发送给程序一个通知，或者执行一个方法，那么即可解决订单关闭问题。 实现：通过监听Redis提供的过期队列来实现，监听过期队列后，如果Redis中某一个KV过期了，那么将向监听者发送消息，监听者可以获取到该键值对的K，注意，是获取不到V的，因为已经过期了，这就是上面所提到的，为什么要保证能通过K来定位到订单，而V为任意值即可。拿到K后，通过K定位订单，并判断其状态，如果是未支付，更新为关闭，或者取消状态即可。 修改redis配置 登录进入redis-cli 客户端（需开启两个客户端窗口，便于查看key过期通知, 使用redis key 过期通知，需手动开启key过期通知功能：1config set notify-keyspace-events Ex 启动监听key过期 1234&gt; PSUBSCRIBE __keyevent@*__:expired1) \"psubscribe\"2) \"__keyevent@*__:expired\"3) (integer) 1 再开启一个客户端,添加test为key,并设置5秒过期 12&gt; setex test 5 testOK 回到监听窗口,查看监听窗口key过期信息 123456789&gt; PSUBSCRIBE __keyevent@*__:expiredReading messages... (press Ctrl-C to quit)1) \"psubscribe\"2) \"__keyevent@*__:expired\"3) (integer) 11) \"pmessage\"2) \"__keyevent@*__:expired\"3) \"__keyevent@0__:expired\"4) \"test\" golang具体代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package cacheimport ( \"shop-server/app\" \"shop-server/model\" \"fmt\" \"strings\" \"unsafe\" \"github.com/gomodule/redigo/redis\" \"github.com/sirupsen/logrus\")var ShopOrderCountDownPrefix = \"shopServerOrderCountDown-\"var orderCountDownChannelTopic = \"__keyevent@0__:expired\"var orderCountDownExpiredTime = 1800 //单位秒 倒计时过期时间30*60 = 1800秒type Order struct &#123; OrderId string //订单id&#125;func (o *Order) CreateOrderSetCacheCountDown() error &#123; cache := app.GetCache() defer cache.Close() _, err := cache.Do(\"SETEX\", ShopOrderCountDownPrefix + o.OrderId, orderCountDownExpiredTime, \"orderCountDown\") if err != nil &#123; fmt.Println(\"redis set expire order countDownExpired and err\", err) return err &#125; return nil&#125;func DealOutDateOrderId() &#123; cache := app.GetCache() defer cache.Close() pubSubConnClient := redis.PubSubConn&#123;cache&#125; //创建一个订阅客户端 err := pubSubConnClient.Subscribe(orderCountDownChannelTopic) //订阅频道 if err != nil &#123; logrus.Println(\"redis subscribe order count down topic err:\", err) &#125; logrus.Debug(\"order countDown wait.....\") for &#123; switch res := pubSubConnClient.Receive().(type) &#123; case redis.Message: message := (*string)(unsafe.Pointer(&amp;res.Data)) logrus.Debug(\"expired message:\", *message) if !strings.HasPrefix(*message, ShopOrderCountDownPrefix) &#123; logrus.Println(\"no expired order id *message:\", *message) break &#125; stringArr := strings.Split(*message, \"-\") outDateOrderId := stringArr[1] //其实这里还可以检查一下订单是否真的已经支付成功 //cancel 订单 order := model.Order&#123;&#125; order.Id = outDateOrderId order.Status = model.OrderStatusCancellation if err := order.SystemAutoCancelOrder(); err != nil &#123; logrus.Errorf(\"error in sysAutoCancelOrder id-err:\", outDateOrderId, err) break &#125; case error: logrus.Errorf(\"error handle...\", err) break &#125; &#125;&#125; 注意事项 因为使用命令来配置的只是存在于缓存中,当redis重启之后就会失效 所以建议采用配置文件启动redis服务 这一点要特别注意 最后开启一个golang的协程就可以了 用来一直不停的处理过期的订单id","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"golang 请求限流实现的集中策略思路","slug":"golang 请求限流实现","date":"2019-07-17T08:29:45.000Z","updated":"2019-07-17T10:25:24.121Z","comments":true,"path":"2019/07/17/golang 请求限流实现/","link":"","permalink":"http://yoursite.com/2019/07/17/golang 请求限流实现/","excerpt":"","text":"几种思路 简单的并发控制 使用计数器实现请求限流 使用golang官方包实现httpserver频率限制 使用Token Bucket(令牌桶算法)实现请求限流 简单的并发控制 利用channel的缓冲通道设定,我们就可以实现并发的限制.我们只要在执行并发的同时,往一个带有缓冲的channel里面写入点东西(随便写点啥, 内容不重要).让并发的goroutine在执行完成后把这个channel里面的东西给读走.这样整个并发的数量就这样控制在这个channel的缓冲区的大小上 比如我们可以用一个bool类型的带缓冲channel作为并发限制的计数器1chLimit := make(chan bool, 1) 然后在并发执行的地方,每次创建一个新的goroutine,都往chLimit里塞个东西12345for i, sleeptime := range input &#123; chs[i] = make(chan string, 1) chLimit &lt;- true go limitFunc(chLimit, chs[i], sleeptime, timeout)&#125; 这里通过go关键字并发执行的是新构造的函数.他在执行完成后,会把chLimit缓冲区里给消费掉一个1234limitFunc := func(chLimit chan bool, ch chan string, task_id, sleeptime, timeout int) &#123; Run(task_id, sleeptime, timeout, ch) &lt;-chLimit&#125; 这样一来,当创建的goroutine数量到达chLimit的缓冲区上线后.主goroutine就挂起祖塞,直到这些goroutine执行完毕,消费掉了chLimit缓冲区的数据,程序才会继续创建新的goroutine.我们并发数量限制的目的也就达到了.下面是完整的代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"fmt\" \"time\")func Run(task_id, sleeptime, timeout int, ch chan string) &#123; ch_run := make(chan string) go run(task_id, sleeptime, ch_run) select &#123; case re := &lt;- ch_run: ch &lt;- re case &lt;- time.After(time.Duration(timeout) * time.Second): re := fmt.Sprintf(\"task id %d, timeout\", task_id) ch &lt;- re &#125;&#125;func run(task_id, sleeptime int, ch chan string) &#123; time.Sleep(time.Duration(sleeptime) * time.Second) ch &lt;- fmt.Sprintf(\"task id %d, Sleep %d second\", task_id, sleeptime) return&#125;func main() &#123; input := []int&#123;3, 2, 1&#125; timeout := 2 chLimit := make(chan bool, 1) chs := make([]string, len(input)) limitFunc := func(chLimit, ch chan string, task_id, sleeptime, timeout int) &#123; Run(task_id, sleeptime, timeout, ch) &lt;- chLimit &#125; startTime := time.Now() fmt.Println(\"Multirun start\") for i, sleeptime := range input &#123; chs[i] = make(chan string, 1) chLimit &lt; true go limitFunc(chLimit, chs[i], i, sleeptime, timeout) &#125; for _, ch := range chs &#123; fmt.Println(&lt;-ch) &#125; endTime := time.Now() fmt.Printf(\"Multissh finsished. Process time %s. Number of task is %d\", endTime.Sub(startTime), len(input))&#125;","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"golang 操作 es相关","slug":"golang es","date":"2019-07-09T08:55:45.000Z","updated":"2019-08-16T07:36:24.691Z","comments":true,"path":"2019/07/09/golang es/","link":"","permalink":"http://yoursite.com/2019/07/09/golang es/","excerpt":"","text":"使用过程踩坑: docker安装elastic docker启动一个es容器 使用es 服务 使用es 创建mapping 使用es 创建client 使用es 创建索引 使用es 删除索引 使用es 删除数据by id 使用es 导入数据import 使用es 设置不分词 全文匹配 使用es 设置多字段混合搜索 使用es 设置嵌套搜索 使用es 设置嵌套搜索和普通多字段混合搜索 docker安装elastic1$ docker pull elasticsearch:6.5.0 docker启动一个es容器1$ docker run --name es -d -e ES_JAVA_OPTS=\"-Xms512m -Xmx512m\" -p 9200:9200 -p 9300:9300 elasticsearch:6.5.0 后面只要使用 docker start es(容器名) 即可 开启该容器了 然后访问Get localhost:9200 发现未启动成功, 查看日志12345678$ docker logs -f esERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144][2019-07-11T03:40:22,889][INFO ][o.e.n.Node ] [yN7SHo9] stopping ...[2019-07-11T03:40:22,954][INFO ][o.e.n.Node ] [yN7SHo9] stopped[2019-07-11T03:40:22,954][INFO ][o.e.n.Node ] [yN7SHo9] closing ...[2019-07-11T03:40:22,977][INFO ][o.e.n.Node ] [yN7SHo9] closed[2019-07-11T03:40:22,984][INFO ][o.e.x.m.j.p.NativeController] [yN7SHo9] Native controller process has stopped - no new native processes can be started 这里提示：vm.max_map_count [65530] is too low, increase to at least [262144]，说max_map_count的值太小了，需要设大到262144 查看max_map_count的值12$ cat /proc/sys/vm/max_map_count65530 重新设置max_map_count的值12$ sysctl -w vm.max_map_count=262144vm.max_map_count = 262144 再次启动容器1$ docker start es 在这里的时候一定要慢一会再刷新 locahost:9200 可能是我的电脑配置太低可以查看日志 看到started就代表启动成功了1[2019-07-11T09:57:37,454][INFO ][o.e.n.Node ] [yN7SHo9] started 再次访问 GET localhost:92001234567891011121314151617`&#123; name: \"yN7SHo9\", cluster_name: \"docker-cluster\", cluster_uuid: \"J0Bb6xooR_OlTZMEtgoPHg\", version: &#123; number: \"6.5.4\", build_flavor: \"default\", build_type: \"tar\", build_hash: \"d2ef93d\", build_date: \"2018-12-17T21:17:40.758843Z\", build_snapshot: false, lucene_version: \"7.5.0\", minimum_wire_compatibility_version: \"5.6.0\", minimum_index_compatibility_version: \"5.0.0\"&#125;, tagline: \"You Know, for Search\"&#125;` 以上表示安装成功 使用es 服务只需要在配置中 使用 localhost:9200即可使用该服务了 使用es创建mapping1234567891011121314151617181920212223242526272829303132const mapping = `&#123; \"settings\":&#123; \"number_of_shards\": 1, //分片数 分布式的概念 暂时还不怎么理解 \"number_of_replicas\": 0 &#125;, \"mappings\":&#123; \"blog\":&#123; \"properties\": &#123; \"id\": &#123; \"type\": \"keyword\" &#125;, \"title\": &#123; \"type\": \"text\" &#125;, \"summary\": &#123; \"type\": \"text\" &#125;, \"tags\": &#123; \"type\": \"nested\", //嵌套 \"properties\": &#123; \"name\": &#123; \"type\": \"keyword\" //keyword 表示不对name分词 必须要完全匹配才行 &#125; &#125; &#125; &#125; &#125; &#125;&#125;`const ESIndexName = \"star\" //索引index 代表数据库 database的概念const ESTypeName = \"blog\" //类型type 代表数据库 table的概念 golang 使用并创建一个client123456789101112131415161718192021222324252627package appimport ( \"fmt\" \"log\" \"github.com/olivere/elastic\")var EsClient *elastic.Clientfunc InitElastic() &#123; host := Config.Elastic.Addr fmt.Println(host) var err error EsClient, err = elastic.NewClient( elastic.SetURL(host), elastic.SetHealthcheck(false), elastic.SetSniff(false), ) if err != nil &#123; log.Println(\"create elastic Client error\", err) return &#125; fmt.Println(\"create elastic Client success\")&#125; 检查并创建mapping索引12345678910111213141516//检查并创建索引func checkMapping() &#123; ctx := context.Background() exists, err := app.EsClient.IndexExists(ESIndexName).Do(ctx) if err != nil &#123; log.Println(\"es blog indexExists err\") &#125; if exists &#123; return &#125; _, err = app.EsClient.CreateIndex(ESIndexName).BodyString(mapping).Do(ctx) if err != nil &#123; log.Println(\"es createIndex err\", err) &#125; log.Println(\"create index ok\")&#125; 批量导入数据12345678910111213141516171819202122232425//批量导入数据func ImportBlog(c *neo.Ctx) (i int, e error) &#123; checkMapping() blog := &amp;model.Blog&#123;&#125; rawQuery := \"status:=:published,reviewed:=:1\" blogs, _, err := blog.List(rawQuery, \"\", 0, -1) if err != nil &#123; return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; bulk := app.EsClient.Bulk().Index(ESIndexName).Type(ESTypeName) for _, b := range *blogs &#123; log.Println(\"tag es add blog id:\", b.Id) bulk.Add(elastic.NewBulkIndexRequest().Id(b.Id).Doc(b)) &#125; _, err = bulk.Do(context.Background()) if err != nil &#123; return http.StatusOK, c.Res.Text(err.Error()) &#125; return http.StatusOK, c.Res.Text(\"import ok\")&#125; 导入单条数据进入es123456789101112131415161718//导入单条数据进入es中//往es里面导入单条blogfunc ImportSingleBlog(blog model.Blog) error &#123; if blog.Status == \"published\" &amp;&amp; blog.Reviewed == true &#123; bulk := app.EsClient.Bulk().Index(ESIndexName).Type(ESTypeName) bulk.Add(elastic.NewBulkIndexRequest().Id(blog.Id).Doc(blog)) _, err := bulk.Do(context.Background()) if err != nil &#123; log.Println(\"es add single blog Do error:\", err) return err &#125; log.Println(\"es add single blog Do Success bId:\", blog.Id) &#125; else &#123; log.Println(\"es add single blog Do failed bId-status-reviewed:\", blog.Id, blog.Status, blog.Reviewed) &#125; return nil&#125; 删除es中的某个索引数据内容1234567891011// @Summary 删除blog// @Tags es// @Success 200 &#123;string&#125; json \"\"// @Router /v1/es/blogs/delete [delete]func DeleteBlog(c *neo.Ctx) (i int, e error) &#123; _, err := app.EsClient.DeleteIndex(ESIndexName).Do(context.Background()) if err != nil &#123; return http.StatusOK, c.Res.Text(err.Error()) &#125; return http.StatusOK, c.Res.Text(\"delete ok\")&#125; 删除某个索引内单条es数据内容123456//删除单条blog从es中func DeleteSingleBlog(blogId string) error &#123; _, err := app.EsClient.Delete().Index(ESIndexName).Type(ESTypeName).Id(blogId).Refresh(\"true\").Do(context.Background()) log.Println(\"delete single blog from es blogId-err:\", blogId, err) return err&#125; query查询blog 嵌套以及多关键字查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func QueryBlog(c *neo.Ctx) (i int, e error) &#123; currentUserId := c.Req.Header.Get(\"user_id\") blogResponse := make([]BlogResponse, 0) keyword := pkg.DefaultQuery(c, \"key\", \"\") log.Println(\"es blog query key:\", keyword) if keyword == \"\" &#123; log.Println(\"es blog query key is empty\") return http.StatusOK, c.Res.Json(map[string]interface&#123;&#125;&#123; \"data\": blogResponse, \"total\": 0, &#125;) &#125; // 请求user-server rpc 存储userSearchLog projectType := 1 //代表BlogServer searchPage := 0 //代表发现页搜索入口 _, err := rpc.AddUserSearchLog(currentUserId, keyword, int64(projectType), int64(searchPage)) if err != nil &#123; log.Println(\"es search tag key addUserSearchLog rpc err-userId-key\", err, currentUserId, keyword) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; // search titleQ := elastic.NewMatchQuery(\"title\", keyword).Boost(2) summaryQ := elastic.NewMatchQuery(\"summary\", keyword).Boost(0.5) tagNameQ := elastic.NewMatchQuery(\"tags.name\", keyword) nestedQ := elastic.NewNestedQuery(\"tags\", tagNameQ) boolQ := elastic.NewBoolQuery().Should(titleQ, summaryQ).Must(nestedQ) res, err := app.EsClient.Search().Index(ESIndexName).Type(ESTypeName). Query(boolQ).Sort(\"createdAt\", false).Do(context.Background()) if err != nil &#123; log.Println(\"es query blog search error:\", err) return http.StatusInternalServerError, c.Res.Text(err.Error()) &#125; var b model.Blog for _, hit := range res.Hits.Hits &#123; json.Unmarshal(*hit.Source, &amp;b) if b.Status == \"onlyAuthorVisible\" &amp;&amp; b.UserId != currentUserId &#123; continue &#125; else &#123; log.Println(\"es blog search blog-id-status-reviewed:\", b.Id, b.Status, b.Reviewed) blogResponse = append(blogResponse, BlogResponse&#123; Blog: b, User: *rpc.GetUserInfo(b.UserId), IsThumb: CheckIsThumb(currentUserId, b.Id), IsStar: CheckIsStar(currentUserId, b.Id), &#125;) &#125; &#125; total := len(blogResponse) return http.StatusOK, c.Res.Json(map[string]interface&#123;&#125;&#123; \"data\": blogResponse, \"total\": total, &#125;)&#125;","categories":[],"tags":[{"name":"golang es","slug":"golang-es","permalink":"http://yoursite.com/tags/golang-es/"}]},{"title":"redis布隆选择器在去重方面的使用","slug":"redis布隆选择器在去重方面的使用","date":"2019-06-11T08:25:00.000Z","updated":"2019-06-11T09:16:38.213Z","comments":true,"path":"2019/06/11/redis布隆选择器在去重方面的使用/","link":"","permalink":"http://yoursite.com/2019/06/11/redis布隆选择器在去重方面的使用/","excerpt":"","text":"redis布隆选择器背景介绍: 1.使用场景：推荐系统给用户推荐新闻，避免重复推送。 需要考虑问题：从用户观看历史中筛选出没有看过的新闻进行推送，就需要数据库中频繁的使用exists进行查询，但是当用户量很大时，数据库很难顶住压力。 解决方法： 1.1.使用缓存？但是日子长了，会浪费很大空间，不是长久之计，不是很好的解决办法。 1.2.这时布隆过滤器就可以很好的解决这个需求了，可以节约90%以上的空间，缺点就是稍微有那么一点不准确，存在一定的误判率，但是对于这个新闻推送的可以忽略。 2.什么布隆过滤器 2.1其实布隆过滤器可以看成是一个不是很准确的set结构，只是在使用它的contains方法判断某个对象是否存在时会出现误判。但是它也不是特别的不精准，只要参数设置合理，那么它的精确度可以控制的足够精准，只会有小小的误判。 2.2当布隆过滤器说某个值存在时，那可能就不存在，如果说某个值不存在时，那肯定就是不存在了 打个比方，当一个人说认识你时可能不认识你，当一个人说不认识你时那肯定就不认识了。当它说见过你时，可能根本没有见过面，只不过可能你的脸和它所认识人中某个人的脸相似度比较高，所以产生误判。 2.3对于上面的场景，当用户看过的新闻，肯定会被过滤掉，对于没有看多的新闻，可能会过滤极少的一部分（误判），但是绝大部分都可以准确识别。这样可以完全保证推送给用户的新闻都是无重复的。 3.需要安装新版的redis版本 这里我们使用docker来安装redislabs/rebloom : docker pull redislabs/rebloom:latest 4.bloomfilter 命令使用 4.1 bf.add 语法:[bf.add key options]127.0.0.1&gt; bf.add users user3 (integer) 1 4.2 bf.exists 语法:[bf.exixts key options]127.0.0.1&gt; bf.exists users user3 (integer) 1 4.3 bf.madd 语法:[bf.madd key …options]127.0.0.1&gt; bf.madd users user4 user5 user6 user7 (integer) 1 (integer) 1 (integer) 1 (integer) 1 4.4 bf.mexists 语法:[bf.mexists key …options]127.0.0.1&gt; bf.mexists users user4 user5 user6 user7 user8 (integer) 1 (integer) 1 (integer) 1 (integer) 1 (integer) 0 4.5 bf.reserve 创建Filter 语法:[bf.reserve key error_rate initial_size]127.0.0.1&gt; bf.reserve books 0.001 10000 ok 5.在golang中的代码的具体实现和运用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import ( \"encoding/json\" \"fmt\" \"log\" \"github.com/gomodule/redigo/redis\")func (blog *Blog) AddUserLog(userId, blogId string) error &#123; cache := app.GetCache() defer cache.Close() _, err := cache.Do(\"BF.ADD\", \"user-read-log-\"+blogId, userId) if err != nil &#123; fmt.Println(\"bloom filer add err\", err) return err &#125; return nil&#125;func (blog *Blog) CheckIsRead(userId string, blogIds []string) ([]int, error) &#123; cache := app.GetCache() defer cache.Close() ints := []int&#123;&#125; for _, blogId := range blogIds &#123; args := []interface&#123;&#125;&#123;\"user-read-log-\" + blogId&#125; args = append(args, userId) intExists, err := redis.Int(cache.Do(\"bf.exists\", args...)) if err != nil &#123; fmt.Println(\"debug charles intExists error arg\", args) intExists = 1 &#125; ints = append(ints, intExists) &#125; return ints, nil&#125;func (blog *Blog) DeleteBlogLogCache(blogId string) error &#123; cache := app.GetCache() defer cache.Close() _, err := cache.Do(\"EXPIRE\", \"user-read-log-\"+blogId, 0) if err != nil &#123; fmt.Println(\"redis set expire bloom filter and err\", err) return err &#125; return nil&#125; 还有一点特别要注意的事项就是, bf只有add和exists两种类似的操作 没有删除操作 如果要是想删除改数据 则使用expire 使该key过期 例如上面演示代码里面提到的DeleteBlogCache函数的用法","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"gorm err不为空和记录未找到的错误区别","slug":"gorm err不为空和记录未找到","date":"2019-06-11T08:00:00.000Z","updated":"2019-06-11T08:15:34.347Z","comments":true,"path":"2019/06/11/gorm err不为空和记录未找到/","link":"","permalink":"http://yoursite.com/2019/06/11/gorm err不为空和记录未找到/","excerpt":"","text":"gorm 中err != nil 并不是真的服务器有错误 因为它会把记录未找到也当成是err 并且此时err != nil:对于查找的记录是单个结构体的话 所以我们在处理gorm给我返回的错误的时候 要特别处理一下 例如下面这种处理方式:123456err == gorm.ErrRecordNotFound &#123; // do something&#125;if err != nil &#123; // do something&#125; 对于查找的记录是结构体数组的时候 判断记录是否为空的时候 则要采取另外一种判断 因为没有记录 并不会报错: 此时我们就只需要判断给我们返回的结构体数组的长度是否是0 来判断是否有查找到记录的 特别要注意这两种情况的判断","categories":[],"tags":[{"name":"goalng gorm","slug":"goalng-gorm","permalink":"http://yoursite.com/tags/goalng-gorm/"}]},{"title":"本地新建仓库并关联远程仓库并且首次提交master分支","slug":"本地新建仓库关联远程仓库并首次提交master","date":"2019-06-11T07:45:45.000Z","updated":"2019-06-11T07:52:54.654Z","comments":true,"path":"2019/06/11/本地新建仓库关联远程仓库并首次提交master/","link":"","permalink":"http://yoursite.com/2019/06/11/本地新建仓库关联远程仓库并首次提交master/","excerpt":"","text":"会出现的问题 首次空的提交远程master分支报错: 处理方法: git commit -m “empty commit” –allow-empty 一般流程的情况是: 先配置信息 * git config --global user.name &quot;xxxxx&quot; * git config --global user.email &quot;xxxx@xx.com&quot; 创建仓库并提交代码 * git init * git remote add origin git@github.***.com:xxxx/***.git * git add -A * git commit -am&quot;首次建立项目提交&quot; * git push origin -u origin master","categories":[],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"golang 逃逸分析","slug":"golang 逃逸分析","date":"2019-05-07T03:19:45.000Z","updated":"2019-05-07T03:36:26.094Z","comments":true,"path":"2019/05/07/golang 逃逸分析/","link":"","permalink":"http://yoursite.com/2019/05/07/golang 逃逸分析/","excerpt":"","text":"golang 逃逸分析什么叫做golang的逃逸分析 逃逸分析是确定指针动态范围的方法,可以分析在程序的哪些地方可以访问指针.当一个变量(或对象)在子程序中被分配,一个指向变量的指针可能逃逸到其他执行线程中,或者去调用子程序.如果使用尾递归优化,对象也可能逃逸到被调用的子程序中.如果一个程序分配一个对象并返回一个该对象的指针,该对象可能在程序中的任何一个地方被访问到,这样指针就成功逃逸了. 如果指针存储在全局变量或者其他数据结构中,也可能发生逃逸,这种情况是当前程序中的指针逃逸.逃逸分析需要确定指针所有可以存储的地方,保证指针的生命周期只在当前进程或线程中. 逃逸分析的好处 减少gc压力,不逃逸的对象分配在栈上,当函数返回时就回收了资源,不需要gc标记清楚 逃逸分析完以后可以确定哪些变量可以分配在栈上,栈的分配比堆快,性能更好 同步消除","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"golang nsq实时消息处理系统源码解读一一基本介绍","slug":"golang nsq","date":"2019-05-06T07:42:45.000Z","updated":"2019-05-07T03:38:40.712Z","comments":true,"path":"2019/05/06/golang nsq/","link":"","permalink":"http://yoursite.com/2019/05/06/golang nsq/","excerpt":"","text":"关于golang中nsq实时消息处理系统的背景介绍 NSQ是由知名短链接服务商bitly用Go语言开发的实时消息处理系统，具有高性能、高可靠、无视单点故障等优点，是一个非常不错的新兴的消息队列解决方案; nsg易于配置和部署，所有参考都通过命令行指定，编译好的二进制文件，没有其它依赖项。而且支持多种消息格式。 源码下载地址 本系列文档下载的源码为0.2.27版本 为了更好的理解源码,最理想的起步当然是先了解nsq的用法, 所以接下来会先讲解nsq的安装和使用 nsq的安装 1.安装golang的环境 2.安装godep,在命令行执行: 1$ go get github.com/kr/godep 如果使用go get安装过程中报错,可以参考另一篇文章:关于go get安装git golang项目时报错的处理办法安装之后,在$GOPATH/bin目录下面就可以看到有godep 的可执行文件,记得讲$GOPATH/bin目录环境配置到系统环境变量$PATH里面,以后在命令行就可以直接输入godep命令来执行一些操作了. 3.安装assert,在命令行执行: 1$ go get github.com/bmizerany/assert 4.接下来开始获取nsq的代码并编译, 在命令行执行 1$ godep get github.com/bitly/nsq/... 注意: 后面有三个点不能少, 执行完之后在$GOPATH/bin目录下面就会看到有很多nsq打头的可执行二进制文件存在,至此安装就结束了","categories":[],"tags":[{"name":"goalng nsq","slug":"goalng-nsq","permalink":"http://yoursite.com/tags/goalng-nsq/"}]},{"title":"golang 中关于数组的相关特性","slug":"golang array","date":"2019-05-06T07:42:45.000Z","updated":"2019-05-06T07:42:59.584Z","comments":true,"path":"2019/05/06/golang array/","link":"","permalink":"http://yoursite.com/2019/05/06/golang array/","excerpt":"","text":"golang 中关于数组的相关特性 值类型 作为参数传递时 不能修改其值 只是一种拷贝 而且还需要特别注意的就是 不同长度的数组类型不一样 123456789101112131415package main import ( \"fmt\")func print(arr [3]int) &#123; arr[0] = 100&#125;func main() &#123; arr1 := [3]int&#123;1, 2, 3&#125; print(arr1)&#125;//结果打印出来的应该仍然还是1，2，3 如果想要改变的话 需要使用指针传递作为参数 但是常见的是使用 slice 切片 自动可以修改原来的数据 数组类型跟长度有关系 可以定义[…]int 让编译器自己去判断数组长度","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"golang 字符串处理","slug":"golang string","date":"2019-05-06T07:41:45.000Z","updated":"2019-05-06T07:48:44.988Z","comments":true,"path":"2019/05/06/golang string/","link":"","permalink":"http://yoursite.com/2019/05/06/golang string/","excerpt":"","text":"字符和字符串处理相关常见操作 特别是对于中文字符的处理以及全球不同字符的处置golang中string实现的背景介绍 golang中string底层是通过byte数组实现的。中文字符在unicode下占2个字节，在utf-8编码下占3个字节，而golang默认编码正好是utf-8。 关于golang中的rune:// rune is an alias for int32 and is equivalent to int32 in all ways. It is// used, by convention, to distinguish character values from integer values. //int32的别名，几乎在所有方面等同于int32//它用来区分字符值和整数值 type rune = int32 获取字节数长度 len 特别记住这一点 len(s)返回的是底层的字节数 英文占一个字节 中文字符在golang中占有两个字节 并不是获得字符串长度 关于utf-8和rune的互相转换 关于含有中文字符串的对于每一个中文字符的遍历处理 强制转换该字符串变成一个[]rune数组 计算字节数 使用range遍历pos, rune pos会不连续 使用[]byte转换获得字节 使用utf8.RuneCountInStriung获得字符数量 golang中海油一个byte数据类型与rune相似，它们都是用来表示字符类型的变量类型。它们的不同在于： byte 等同于int8，常用来处理ascii字符 rune 等同于int32,常用来处理unicode或utf-8字符 12345678910111213141516171819202122232425262728293031323334353637383940414243package main import ( \"fmt\" \"unicode/utf8\")func main() &#123; s := \"Yes我爱慕课网!\" //UTF-8编码方式 中文 可变长编码方式 英文是一字节方式 中文是3字节方式存储 fmt.Println(s) //查看字符的具体存储 X打出字节的具体数字 16进制 每个字符的ascii码值 for _, b := range []byte(s) &#123; //utf-8编码 fmt.Println(\"%X\\n\", b) &#125; fmt.Println() for i, ch := range s &#123; //unicode编码 i是每个字符的开始字节数 ch is a rune(int32) 一个四字节的整数 fmt.Printf(\"(%d %X)\", i , ch) &#125; fmt.Println() fmt.Println(\"Rune count:\", utf8.RuneCountInString(s)) //获取rune个数 也是获取字符串长度的方法之一 //常用方法 for i, ch := range []rune(s) &#123; //获得一个rune数组 一个下标一个英文字符或者一个中文字符 获取字符串长度方法二 fmt.Println(\"(%d %c\"), i, ch) &#125; fmt.Println() bytes := []bytes(s) // for len(bytes) &gt; 0 &#123; ch, size := utf8.DecodeRune(bytes) fmt.Printf(\"(%c %v)\", ch, size) bytes = bytes[size:] &#125;&#125;运行结果:Yes我爱慕课网!59 65 73 E6 88 91 E7 88 B1 E6 85 95 E8 AF BE E7 BD 91 21 //utf-8编码(0 59)(1 65)(2 73)(3 6211)(6 7231)(9 6155)(12 8BFE)(15 7F51)(18 21) //unicode编码(0 Y)(1 e)(2 s)(3 我)(4 爱)(5 慕)(6 课)(7 网)(8 !) //第几个字符是谁(Y 1)(e 1)(s 1)(我 3)(爱 3)(慕 3)(课 3)(网 3)(! 1) 1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"unicode/utf8\")func main() &#123; var str = \"hello 你好\" //golang中string底层是通过byte数组实现的，座椅直接求len 实际是在按字节长度计算 所以一个汉字占3个字节算了3个长度 fmt.Println(\"len(str):\", len(str)) //以下两种都可以得到str的字符串长度 //golang中的unicode/utf8包提供了用utf-8获取长度的方法 fmt.Println(\"RuneCountInString:\", utf8.RuneCountInString(str)) //通过rune类型处理unicode字符 fmt.Println(\"rune:\", len([]rune(str)))&#125;运行结果:len(str): 12RuneCountInString: 8rune: 8","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"etcd在mac系统中的安装与使用","slug":"golang mac etcd安装与使用","date":"2019-05-06T07:41:45.000Z","updated":"2019-05-06T07:50:25.395Z","comments":true,"path":"2019/05/06/golang mac etcd安装与使用/","link":"","permalink":"http://yoursite.com/2019/05/06/golang mac etcd安装与使用/","excerpt":"","text":"etcd在mac系统中的安装与使用 进入etcd官网提供的连接， 点击GitHub Project, 然后选择release版本下载编译好的版本代码包 解压下载好的代码包 cd 进入解压后的代码包 启动server端 nohup ./etcd –listen-client-urls ‘http://0.0.0.0:2379&#39; –advertise-client-urls ‘http://0.0.0.0:2379&#39; &amp; client客户端连接使用 ETCDCTL_API=3 ./etcdctl put “name” “fengjun” ETCDCTL_API=3 ./etcdctl get “name” etcd特性总结 对于key前缀相同的有序排列存储在系统中 例如: ETCDCTL_API=3 ./etcdctl put “/cron/jobs/job1” “{…job1}” ETCDCTL_API=3 ./etcdctl put “/cron/jobs/job2” “{…job2}” 然后可以按照key前缀设置来查找集合 ETCDCTL_API=3 ./etcdctl get “/cron/jobs/“ –prefix /cron/jobs/job1 {…job1} /cron/jobs/job2 {…job2} 在新开的终端会话界面使用watch命令检测 进入解压后的文件夹中 ETCDCTL_API=3 ./etcdctl watch “/cron/jobs/“ –prefix ETCDCTL_API=3 ./etcdctl put “/cron/jobs/job2” “{…1111}” //修改 新开的终端会显示:PUT/cron/jobs/job2{…1111} 获取etcd golang客户端的代码 在上面打开的etcdgithub项目代码里面 clientv3 etcd/clientv3 is the official Go etcd client for v3. golang安装客户端代码方式 Install go get github.com/coreos/etcd/client //或者使用gopm工具 或者进入golang中国下载该包 然后入项目中","categories":[],"tags":[{"name":"goalng etcd mac","slug":"goalng-etcd-mac","permalink":"http://yoursite.com/tags/goalng-etcd-mac/"}]},{"title":"golang字符串时间戳转换成time.Time类型","slug":"golang字符串时间戳转换成time.Time类型","date":"2019-05-06T07:09:45.000Z","updated":"2019-05-06T07:21:05.302Z","comments":true,"path":"2019/05/06/golang字符串时间戳转换成time.Time类型/","link":"","permalink":"http://yoursite.com/2019/05/06/golang字符串时间戳转换成time.Time类型/","excerpt":"","text":"时间转换的原理是: 将原先的字符串时间戳转换为int64位, 再使用time.Unix(v, 0)转换成time类型的时间戳 需要相关使用的函数有: unix64, _ := strconv.ParseInt(unixStr, 10, 64) time.Unix(v, 0) 代码示例:123var startTime time.TimestartTimeInt64, _ := strconv.ParseInt(start, 10, 64)startTime = time.Unix(startTimeInt64, 0)","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"golang字符串处理","slug":"golang字符串处理","date":"2019-05-06T06:12:01.000Z","updated":"2019-05-06T07:21:49.157Z","comments":true,"path":"2019/05/06/golang字符串处理/","link":"","permalink":"http://yoursite.com/2019/05/06/golang字符串处理/","excerpt":"","text":"关于golang中字符串处理相关注意事项 len(str) 获得是该字符串的字节数中文字符占3个字节 英文字母占一个字节如果想要获得数组 一个下标一个中文字符或者英文字符的话,需要使用[]rune()来强制转换","categories":[],"tags":[{"name":"goalng","slug":"goalng","permalink":"http://yoursite.com/tags/goalng/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-05-06T05:10:58.498Z","updated":"2019-05-06T05:10:58.498Z","comments":true,"path":"2019/05/06/hello-world/","link":"","permalink":"http://yoursite.com/2019/05/06/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}